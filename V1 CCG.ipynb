{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4206ef26",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "flex_source_link = \"https://github.com/et22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c8d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from scipy.io import loadmat\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from ipywidgets import interact, interactive, interactive_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import chi2_contingency\n",
    "                      \n",
    "#import networkx as nx\n",
    "#from pyvis.network import Network\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37b0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cont_mtx(cat_row, cat_col, cont, num_rows):\n",
    "    cat_rows = np.arange(num_rows)+1\n",
    "    cat_cols = np.arange(num_rows)+1\n",
    "    cont_mtx = np.zeros((cat_rows.size, cat_cols.size))\n",
    "    for idxr, row in np.ndenumerate(cat_rows):\n",
    "        for idxc, col in np.ndenumerate(cat_cols):\n",
    "            cont_mtx[idxr, idxc] = np.nanmean(cont[np.logical_and(cat_row == row,cat_col == col)]);\n",
    "    return cont_mtx;\n",
    "\n",
    "def make_prop_mtx(cat_row, cat_col, numer_var, num_rows):\n",
    "    cat_rows = np.arange(num_rows)+1\n",
    "    cat_cols = np.arange(num_rows)+1\n",
    "    prop_numer = np.zeros((cat_rows.size, cat_cols.size))\n",
    "    prop_denom = np.zeros((cat_rows.size, cat_cols.size))\n",
    "    for idxr, row in np.ndenumerate(cat_rows):\n",
    "        for idxc, col in np.ndenumerate(cat_cols):\n",
    "            subset = np.logical_and(cat_row == row,cat_col == col)\n",
    "            rev_subset = np.logical_and(cat_row == col, cat_col == row)\n",
    "            either_subset = np.logical_or(subset, rev_subset)\n",
    "            prop_numer[idxr, idxc] = np.nansum(numer_var[subset])\n",
    "            prop_denom[idxr, idxc] = np.size(numer_var[subset])\n",
    "            \n",
    "    prop_mtx = np.divide(prop_numer, prop_denom)\n",
    "    return prop_mtx, prop_numer, prop_denom\n",
    "\n",
    "def get_checkbox_inclusions(boxes, pre_tlabels, post_tlabels):\n",
    "    subset = np.ones_like(pre_tlabels, dtype='bool')\n",
    "    for idx, box in enumerate(boxes):\n",
    "        if not box.value:\n",
    "            ex_val = idx + 1\n",
    "            subset = np.logical_and.reduce((subset, pre_tlabels!=ex_val, post_tlabels!=ex_val))\n",
    "    return subset\n",
    "            \n",
    "def get_subset(change):\n",
    "    metric = ccg_selection.value\n",
    "    \n",
    "    maxima = maxima_selection.value\n",
    "    lag_max = lag_selection.value[1]\n",
    "    lag_min = lag_selection.value[0]\n",
    "    \n",
    "    std_max = std_selection.value[1]\n",
    "    std_min = std_selection.value[0]\n",
    "    \n",
    "    area_max = area_selection.value[1]\n",
    "    area_min = area_selection.value[0]\n",
    "    \n",
    "    ccg_curr = ccg_data[metric][0][0].copy()\n",
    "    ccg_fields = ccg_data['ccg'][0][0].dtype.names\n",
    "    \n",
    "    \n",
    "    noise_std = ccg_curr['noise_std' + noise_selection.value]\n",
    "    noise_mean = ccg_curr['noise_mean' + noise_selection.value]\n",
    "    \n",
    "    lag_subset = np.logical_and(ccg_curr[maxima+'_lag']>=lag_min, ccg_curr[maxima+'_lag']<=lag_max)\n",
    "    maxima_subset = np.logical_and(ccg_curr[maxima+'s']>=(std_min*noise_std+noise_mean), ccg_curr[maxima+'s']<=(std_max*noise_std+noise_mean)) \n",
    "    area_subset = np.logical_and(ccg_curr['area']>=area_min, ccg_curr['area']<=area_max)    \n",
    "    \n",
    "    cl_subset = get_checkbox_inclusions(cl_checkboxes[1:],ccg_curr['pre_cl'],ccg_curr['post_cl'])\n",
    "    ct_subset = get_checkbox_inclusions(ct_checkboxes[1:],ccg_curr['pre_ct'],ccg_curr['post_ct'])\n",
    "    sc_subset = get_checkbox_inclusions(sc_checkboxes[1:],ccg_curr['pre_sc'],ccg_curr['post_sc'])\n",
    "\n",
    "    subset = np.logical_and.reduce((lag_subset, maxima_subset, area_subset, cl_subset, ct_subset, sc_subset))\n",
    "    \n",
    "    for field in ccg_fields:\n",
    "        if field != 'config' and field != 'cluster' and field != 'ccg_control':\n",
    "            ccg_curr[field] = ccg_curr[field][np.squeeze(subset)]\n",
    "            \n",
    "    return ccg_curr, maxima, metric, subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8b2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clustering functions \n",
    "def cluster_flow(ccgs):\n",
    "    num_elems = np.min([ccgs.shape[0], 10000]) # choose at most 10000 ccgs for clustering for efficiency purposes\n",
    "    inc_idx = np.random.choice(ccgs.shape[0], size=num_elems, replace=True, p=None)\n",
    "    ccgs = ccgs[inc_idx,:]\n",
    "    \n",
    "    # smooth \n",
    "    # smoothed = gaussian_filter1d(ccgs, 1, axis=1)\n",
    "    # smmothed_base = smoothed.copy()\n",
    "    smoothed = ccgs\n",
    "    \n",
    "    # rescale\n",
    "    smoothed = np.transpose(np.transpose(smoothed) - np.ndarray.min(smoothed, axis=1)) # subtract min, new min = 0\n",
    "    one_over_range = 1/np.ptp(smoothed, axis=1)\n",
    "    smoothed = smoothed*one_over_range[:,np.newaxis]     \n",
    "    \n",
    "    # pca\n",
    "    pca_obj = PCA(n_components=smoothed.shape[1])\n",
    "    x_new = np.ascontiguousarray(pca_obj.fit_transform(smoothed))\n",
    "    \n",
    "    for idx, curr_var in enumerate(pca_obj.explained_variance_ratio_):\n",
    "        var_explained = np.sum(pca_obj.explained_variance_ratio_[0:idx])\n",
    "        k_comp = idx\n",
    "        if var_explained>.95:\n",
    "            break\n",
    "    \n",
    "    print(k_comp)\n",
    "    # cluster        \n",
    "    cluster_obj = AgglomerativeClustering(n_clusters = 3, compute_full_tree = True, compute_distances=True)\n",
    "    cluster_obj.fit(x_new[:,0:k_comp])\n",
    "    \n",
    "    return inc_idx, smoothed, cluster_obj\n",
    "\n",
    "def find_number_of_clusters(ccgs, range_n_clusters):\n",
    "    score = []\n",
    "    for k in range_n_clusters:\n",
    "        cluster_obj = AgglomerativeClustering(n_clusters=k, compute_labels=True)\n",
    "        cluster_labels = cluster_obj.fit_predict(ccgs)\n",
    "        if k>1:\n",
    "            silhouette_samps = silhouette_samples(ccgs, cluster_labels)\n",
    "            sihouette_score=np.average(silhouette_samps, weights=weights)\n",
    "        else:\n",
    "            sihouette_score=0\n",
    "        score.append(sihouette_score)\n",
    "    return score\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a054d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clustering plot functions\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "    plt.show()\n",
    "    \n",
    "## plot cluster templates\n",
    "def plot_cluster_templates(ccgs, idxes):\n",
    "    uq_idxes = np.unique(idxes)\n",
    "    print(uq_idxes)\n",
    "    for idx in uq_idxes:\n",
    "        template = np.mean(ccgs[idxes==idx], axis=0)\n",
    "        plt.subplot(1,uq_idxes.size,idx)\n",
    "        h = plt.plot(range(-10, -10 +template.size),template, 'o-')\n",
    "        plt.xlabel(\"tau\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "                \n",
    "## plot cluster examples\n",
    "def plot_cluster_examples(ccgs, idxes):\n",
    "    uq_idxes = np.unique(idxes)\n",
    "    for idx in uq_idxes:\n",
    "        ex_ccgs = ccgs[idxes==idx]\n",
    "        ex_idxes = np.random.choice(ex_ccgs.shape[0], size = 3, replace=True)\n",
    "        for idx1, example in enumerate(ex_idxes):\n",
    "            plt.subplot(3,uq_idxes.size,(idx1)*3+idx)\n",
    "            h = plt.plot(range(-10, -10 + ex_ccgs[example].size),ex_ccgs[example], 'o-')\n",
    "            if idx1>2:\n",
    "                plt.xlabel(\"tau\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "                \n",
    "## plot cluster heatmaps\n",
    "def plot_cluster_heatmaps(idxes, ccg_curr, pre_lab, post_lab, num_rows, row_labels):\n",
    "    uq_idxes = np.unique(idxes)\n",
    "    for idx in uq_idxes:\n",
    "        mtx, numer, denom = make_prop_mtx(np.squeeze(ccg_curr[pre_lab]), np.squeeze(ccg_curr[post_lab]), np.squeeze(idxes==idx), num_rows)\n",
    "        df = pd.DataFrame(mtx, columns=row_labels, index=row_labels)\n",
    "        \n",
    "        sns.heatmap(df, cmap=\"vlag\", annot=True)\n",
    "        plt.show()\n",
    "        \n",
    "## plot cluster network\n",
    "#def plot_cluster_network(idxes, ccg_curr):\n",
    "    #G = nx.DiGraph()\n",
    "    # edge_list = []\n",
    "    #inc_idxes = np.random.choice(ccg_curr['pre_id'].shape[0], size = 400, replace=True)\n",
    "\n",
    "    #for idx, id_val in enumerate(ccg_curr['pre_id'][inc_idxes]):\n",
    "    #     edge_list.append((int(ccg_curr['pre_id'][inc_idxes[idx]]), int(ccg_curr['post_id'][inc_idxes[idx]]))) #, {'color', str(idxes[idx])}\n",
    "    #print(edge_list)\n",
    "    #G.add_edges_from(edge_list)\n",
    "    #print(G.number_of_nodes())\n",
    "    #print(G.number_of_edges())\n",
    "    #nx.draw(G)\n",
    "    #plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e670466",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccg_data = loadmat('int_output/combined_ccg_data.mat', chars_as_strings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5836f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccg_data = ccg_data['ccg_data'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e98cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cat variable labels\n",
    "labels = {'cl': [\"2/3\", \"4a/b\", \"4cα\", \"4cβ\", \"5\", \"6\", \"WM\"], \n",
    "         'sc': [\"Complex\", \"Simple\"],\n",
    "         'ct': [\"AS\", \"FS\", \"RM\", \"RL\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb603412",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c2b44",
   "metadata": {
    "tags": [
     "no-header"
    ]
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7106693",
   "metadata": {
    "tags": [
     "body",
     "background-color=black"
    ]
   },
   "source": [
    "# Correlated Neural Activity in Macaque V1\n",
    "---\n",
    "\n",
    "Welcome to the interactive analysis tool for *Functional Connectivity of Neurons within Single Cortical Columns Measured with Neuropixels*! \n",
    "\n",
    "This tool is designed to allow the community to explore a large dataset of Neuropixel recordings from macaque V1 and test hypotheses regarding functional connectivity among distinct layers and functional and putative cell types. \n",
    "## Tutorial \n",
    "1. Click on the 'Input Selection' page and browse the input selection options. If you're satisfied with the defaults used in the paper, click the 'plot' button on the right side of the page. Any time you change the inputs, you must click the plot button on this page to update the results. \n",
    "2. Click on the 'CCG examples' page and browse some example CCGs that were included with the selected inclusion criteria.  \n",
    "3. Click on the '|Tau| Heatmap page'. The heatmaps displays mean |Tau| for pre-/post- layer pairs where the pre-synaptic layer is the row and the post-synaptic layer is the column. Most pages display both a main chart and pairwise comparisons/significance tests. Try changing the selected layers in the pairwise comparison input box and viewing the results in the histogram on the bottom right.\n",
    "4. Click back on the 'Input Selection' page. On the 'Metric Input' tab, change the 'plot by' option from layer to functional cell type, then click the 'plot' button on the right side of the page. \n",
    "5. Click back on the '|Tau| Heatmap page'. Notice that the both the categories on the heatmap axes and in the pairwise comparison box have changed from layers to functional cell types. \n",
    "6. Browse the rest of the output pages and experiment with other input parameters. At a minimum, we recommend examining the three CCG metrics, 'plot by' options, removing the area exclusion criteria, and removing synchronous pairs (select $\\tau$ range as 1-10). \n",
    "\n",
    "\n",
    "## Documentation \n",
    "\n",
    "### Input\n",
    "####  CCG Metrics\n",
    "We provide three CCG metrics that arise from applying different normalizatons to the raw cross-correlation. **Efficacy** is the proportion of pre-synaptic spikes followed by a post-synaptic spike.\n",
    "**Contribution** is the proportion of post-synaptic spikes preceded by a pre-synaptic spike. **Geom. Mean** is the raw CCG normalized by the geometric mean of the firing rates of the pre- and post-synaptic neurons. More formally, theraw cross-correlation, $ CCG(\\tau) $, is defined as follows:\n",
    "$$ CCG(\\tau) = \\sum_{i=1}^M\\sum_{t=\\tau+1}^Nx_{pre}^i(t=\\tau)\\times x_{post}^i(t) $$\n",
    "where $\\tau$ is the time lag, $M$ is the number of trials, $N$ is the number of 1 ms time bins per trial, and $x_{pre(post)}^i(t)$ is 1 if the pre- (post-) synaptic neuron fired a spike in time bin t and 0 otherwise. \n",
    "\n",
    "Then, the efficacy CCG is defined as follows:\n",
    "$$CCG(\\tau)_{eff.} = \\frac{ CCG(\\tau)}{\\sum_{i=1}^M\\sum_{t=\\tau+1}^Nx_{pre}^i(t-\\tau)}$$\n",
    "\n",
    "The contribution CCG is defined as follows:\n",
    "$$CCG(\\tau)_{contr.} = \\frac{ CCG(\\tau)}{\\sum_{i=1}^M\\sum_{t=\\tau+1}^Nx_{post}^i(t)}$$\n",
    "\n",
    "The geom. mean CCG is defined as follows:\n",
    "$$CCG(\\tau)_{g.m.}= \\frac{ CCG(\\tau)}{\\sqrt{(\\sum_{i=1}^M\\sum_{t=\\tau+1}^N x_{pre}^i(t-\\tau))\\times(\\sum_{i=1}^M\\sum_{t=\\tau+1}^N x_{post}^i(t))}}$$\n",
    "\n",
    "CCGs were corrected by subtracting the expected value of the CCG produced from jittered spike trains with a jitter window of 25 ms. The jitter method preserves spike train firing rates and PSTH within the 25 ms window. Thus, jitter-correction eliminates both stimulus-locked and long-timescale correlations.  \n",
    "\n",
    "####  CCG Attributes\n",
    "The **peak** is the maximum value of the corrected CCG. When examining peaks, $\\tau$ is the time lag of the peak.\n",
    "\n",
    "The **trough** is the minimum value of the corrected CCG. When examining troughs, $\\tau$ is the time lag of the trough. \n",
    "\n",
    "The **area** is the integral under the CCG for $|\\tau|<=10$. \n",
    "\n",
    "#### Exclusion Criteria \n",
    "We provide four exclusion criteria that can be used to subset CCGs into significant/non-significant divisions. \n",
    "1. CCGs that are greater than (less than) $k$ standard deviations above (below) the mean noise distribution are included to examine excitatory (inhibitory) interactions. The **noise distribution** is defined as either the entire CCG or the CCG 'tails' at $100>|\\tau|>50$. $k$ and the noise distribution option is determined by user selection. \n",
    "2. CCGs with \\tau inside of the range $\\tau_1-\\tau_2$ are included. $\\tau_1, \\tau_2$ are determined by user selection.\n",
    "3. CCGs with area within a specific range are included.\n",
    "4. CCGs that include neurons in a specific layer or with a specific functional or putative cell type are included.\n",
    "\n",
    "#### Single Neuron Attributes\n",
    "**Layer** refers to common layer divisions of macaque V1 including layers 2/3, 4a/b, 4c$\\alpha$, 4c$\\beta$, 5, 6, and WM. Layer divisions were determined based on CSD across the length of the probe. \n",
    "\n",
    "**Functional Cell Type** refers to simple vs complex cells. Simples cells have F1/F0 ratio greater than 1 and complex cells have F1/F0 ratio less than 1.\n",
    "\n",
    "**Putative Cell Type** refers to axonal-spikes (AS), fast-spking (FS), regular-spiking medium (RM), and regular-spiking long (RL) divisions. These divisions are derived from waveform peak-trough difference as described in Zhu et al. 2021. \n",
    "\n",
    "### Output\n",
    "\n",
    "#### Clustering\n",
    "Significant CCGs are rescaled between 0 and 1. Then, PCA is run on rescaled CCGs with the value of CCGs at 11 (21) timepoints as  features. $x$ PCs are then used for aglommerative clustering with Ward linkage where $x$ is the number of PCs neccesary to explain 95% of variance in input data.\n",
    "\n",
    "The optimal number of clusters used in the manuscript (3) was identified using a combination of silhouette criterion and within-cluster sums of squares. For efficiency, the number of clusters in the tool is fixed at 3, and if the number of significant CCGs exceeds 10,000, a random subset of 10,000 significant CCGs is used for clustering.\n",
    "  \n",
    "\n",
    "<center>\n",
    "<img src='https://static.wixstatic.com/media/2997bf_9718a381f05f4cc9a721428ad26c6639~mv2.jpeg/v1/crop/x_35,y_47,w_1223,h_614/fill/w_388,h_195,al_c,q_80,usm_0.66_1.00_0.01/Image%207-17-20%20at%203_45%20PM.webp'>\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b95599",
   "metadata": {},
   "source": [
    "# Input Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81aa638",
   "metadata": {
    "tags": [
     "tabs",
     "no-nav-fill",
     "no-fade",
     "size=900"
    ]
   },
   "source": [
    "## Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c228b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "default_label = widgets.Label(value=\"Default settings:\")\n",
    "default_selection = widgets.RadioButtons(\n",
    "    options=[('s.d. (smith/kohn)', 'sd'),('s.d.+area (ours)', 'sd_area')],\n",
    "    value='sd_area',\n",
    "    disabled=False\n",
    ")\n",
    "default_button = widgets.Button(\n",
    "    description='reset to defaults',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "plot_button = widgets.Button(\n",
    "    description='plot', \n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "ccg_label = widgets.Label(value=\"Metric:\")\n",
    "ccg_selection = widgets.RadioButtons(\n",
    "    options=[('Efficacy', 'ccg'),('Contribution', 'ccgpren'), ('Geom. mean','ccgn')],\n",
    "    value='ccg',\n",
    "    disabled=False\n",
    ")\n",
    "maxima_label = widgets.Label(value=\"Maxima:\")\n",
    "maxima_selection = widgets.RadioButtons(\n",
    "    options=[('Peaks', 'peak'), ('Troughs', 'trough')],\n",
    "    value='peak',\n",
    "    disabled=False\n",
    ")\n",
    "noise_label = widgets.Label(value=\"Noise Distribution:\")\n",
    "noise_selection = widgets.RadioButtons(\n",
    "    options=[('CCG (0-100 ms)', ''),('CCG tail (50-100 ms)', '2')],\n",
    "    value='',\n",
    "    disabled=False,\n",
    ")\n",
    "std_label = widgets.Label(value=\"Maxima > or < k std. + mean noise:\")\n",
    "std_selection = widgets.FloatRangeSlider(\n",
    "    value=[3, 10],\n",
    "    min=-10.0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    ")\n",
    "lag_label = widgets.Label(value=\"Tau:\")\n",
    "lag_selection = widgets.IntRangeSlider(\n",
    "    value=[0, 10],\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "area_label = widgets.Label(value=\"CCG integral over |Tau|=0-10:\")\n",
    "area_selection = widgets.FloatRangeSlider(\n",
    "    value=[.05, .5],\n",
    "    min=-.5,\n",
    "    max=.5,\n",
    "    step=.01,\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.2f',\n",
    ")\n",
    "\n",
    "cl_label = widgets.Label(value=\"Layer:\")\n",
    "cl_checkboxes = [widgets.Checkbox(value=True, indent=True, description=label) for label in labels['cl']]\n",
    "cl_checkboxes[6].value = False; # don't include WM in default layers\n",
    "cl_checkboxes.insert(0,cl_label);\n",
    "cl_selection = widgets.VBox(children=cl_checkboxes)\n",
    "\n",
    "ct_label = widgets.Label(value=\"Putat. type:\")\n",
    "ct_checkboxes = [widgets.Checkbox(value=True, indent=True, description=label) for label in labels['ct']]\n",
    "ct_checkboxes.insert(0,ct_label);\n",
    "ct_selection = widgets.VBox(children=ct_checkboxes)\n",
    "\n",
    "sc_label = widgets.Label(value=\"Func. type:\")\n",
    "sc_checkboxes = [widgets.Checkbox(value=True, indent=True, description=label) for label in labels['sc']]\n",
    "sc_checkboxes.insert(0,sc_label);\n",
    "sc_selection = widgets.VBox(children=sc_checkboxes)\n",
    "ex_selection = widgets.HBox([cl_selection, ct_selection, sc_selection])\n",
    "\n",
    "plot_label = widgets.Label(value=\"Plot By:\")\n",
    "plot_selection = widgets.RadioButtons(\n",
    "    options=[('Layer', 'cl'), ('Putative cell type', 'ct'), ('Functional cell type', 'sc')],\n",
    "    value='cl',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "slide_ex_label = widgets.Label(value=\"Sliders determine which CCGs to include in the analysis, e.g., selecting a range for Tau of 1-10 means CCGs with Tau = 0 are excluded.\")\n",
    "check_ex_label = widgets.Label(value=\"Checkboxes determine which neurons to include in the analysis, e.g., checking W.M. means neurons in white matter will be included in figures.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05ab10",
   "metadata": {},
   "source": [
    "### Metric Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504a81a7",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a6b466e9e64f78b876d4eb6d0314d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Metric:'), RadioButtons(options=(('Efficacy', 'ccg'), ('Contributio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ignore for now widgets.VBox([default_label, default_selection, default_button]),\n",
    "widgets.HBox([\n",
    "              widgets.VBox([ccg_label, ccg_selection]), \n",
    "              widgets.VBox([maxima_label, maxima_selection]),\n",
    "              widgets.VBox([noise_label, noise_selection]),\n",
    "              widgets.VBox([plot_label, plot_selection])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f735bf",
   "metadata": {},
   "source": [
    "### CCG Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ad722e",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73c7b83744e4c0c80f67fbf6bb2a208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='Sliders determine which CCGs to include in the analysis, e.g., sele…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([widgets.VBox([slide_ex_label, std_label, std_selection,lag_label,lag_selection, area_label, area_selection]),\n",
    "              widgets.VBox([check_ex_label, ex_selection])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6982102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ccg_data['ccg'][0][0]['cluster'][0][0]\n",
    "df = pd.DataFrame({'session': np.squeeze(data['Cluster_session']),\n",
    "              'celllayer': np.squeeze(data['Cluster_celllayer']),\n",
    "              'cell depth': np.squeeze(data['Cluster_celldepth']),\n",
    "               'celltype': np.squeeze(data['Cluster_celltype']), \n",
    "              'MI_max': np.squeeze(data['Cluster_MI_max']), \n",
    "              'simpcomp': np.squeeze(data['Cluster_simpcomp'])})\n",
    "\n",
    "def on_layer_change(change):\n",
    "    depth = data['Cluster_celldepth']\n",
    "    new_layers = np.sum(depth<l23.value,depth<l4ab.value,depth<l4ca.value,depth<l4cb.value,depth<l5.value,depth<l6.value,depth<lWM.value)\n",
    "    new_layers[new_layers==0] = float(\"NaN\")\n",
    "    \n",
    "def layer_picker_output(ses_num):\n",
    "    df_ses1 = df[df[\"session\"]==ses_num]\n",
    "\n",
    "    y = []\n",
    "    for i in range(len(labels['cl'])):\n",
    "        y.append(np.max(np.squeeze(data['Cluster_celldepth'])\n",
    "                        [np.squeeze(np.logical_and(data['Cluster_session']==ses_num,data['Cluster_celllayer']==(i+1)))]));\n",
    "\n",
    "    l23=widgets.IntSlider(value=int(y[0]), min=0, max=3000,description=labels['cl'][0], continuous_update=False)\n",
    "    l4ab=widgets.IntSlider(value=int(y[1]), min=0, max=3000,description=labels['cl'][1], continuous_update=False)\n",
    "    l4ca=widgets.IntSlider(value=int(y[2]), min=0, max=3000,description=labels['cl'][2], continuous_update=False)\n",
    "    l4cb=widgets.IntSlider(value=int(y[3]), min=0, max=3000,description=labels['cl'][3], continuous_update=False)\n",
    "    l5=widgets.IntSlider(value=int(y[4]), min=0, max=3000,description=labels['cl'][4], continuous_update=False)\n",
    "    l6=widgets.IntSlider(value=int(y[5]), min=0, max=3000,description=labels['cl'][5], continuous_update=False)\n",
    "    lWM=widgets.IntSlider(value=int(y[6]), min=0, max=3000,description=labels['cl'][6], continuous_update=False)\n",
    "    ui = widgets.VBox([l23, l4ab, l4ca,l4cb, l5, l6,lWM])\n",
    "\n",
    "    def plot_layer_lines(l23, l4ab, l4ca, l4cb, l5, l6, lWM):\n",
    "        plt.figure(2)\n",
    "        ax1 = sns.kdeplot(data=df_ses1, y=\"cell depth\", hue=\"simpcomp\", fill=False, cut=0, bw_adjust=.4)\n",
    "        ax1_lim = ax1.get_xlim()\n",
    "        ax1.set_xlim((ax1_lim[0],2*ax1_lim[1])) \n",
    "        plt.legend(labels['sc'], frameon=False,loc='upper left')\n",
    "        plt.xticks([])\n",
    "        plt.xlabel('')\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "\n",
    "        ax2 = ax1.twiny()\n",
    "        sns.kdeplot(data=df_ses1, y=\"cell depth\", hue=\"celltype\",fill=False, ax=ax2, cut=0, bw_adjust=.4)\n",
    "        ax2_lim = ax2.get_xlim()\n",
    "        ax2.set_xlim((ax2_lim[0]-ax2_lim[1],ax2_lim[1])) \n",
    "        plt.legend(labels['ct'], frameon=False, loc='upper center')\n",
    "        plt.xticks([])\n",
    "        plt.xlabel('')\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['bottom'].set_visible(False)\n",
    "\n",
    "        layer_min = []\n",
    "        x_vals = []\n",
    "        layer_lab = []\n",
    "        ax3 = ax1.twiny()\n",
    "\n",
    "        for i in range(len(labels['cl'])):\n",
    "            if i == 0:\n",
    "                y = l23\n",
    "            elif i == 1:\n",
    "                y = l4ab\n",
    "            elif i == 2:\n",
    "                y = l4ca\n",
    "            elif i == 3:\n",
    "                y = l4cb\n",
    "            elif i == 4:\n",
    "                y = l5\n",
    "            elif i == 5:\n",
    "                y = l6\n",
    "            elif i == 6:\n",
    "                y = lWM\n",
    "\n",
    "            layer_min.append(y)\n",
    "            layer_min.append(y)\n",
    "            layer_lab.append(labels['cl'][i])\n",
    "            layer_lab.append(labels['cl'][i])\n",
    "            x_vals.append(ax3.get_xlim()[0])\n",
    "            x_vals.append(ax3.get_xlim()[1])\n",
    "\n",
    "        df_layer = pd.DataFrame({'x': x_vals, 'y': layer_min, 'layer_lab':layer_lab})\n",
    "\n",
    "        sns.lineplot(data=df_layer, x='x', y='y', hue='layer_lab', ax=ax3, palette=\"crest\" )\n",
    "        plt.legend(labels['cl'], frameon=False, loc='upper right')\n",
    "        plt.xticks([])\n",
    "        plt.xlabel('')\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        ax3.spines['bottom'].set_visible(False)\n",
    "        ax3.set_ylim(ax3.get_ylim()[0], ax3.get_ylim()[1]*1.5)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    output = interactive_output(plot_layer_lines, {'l23':l23,\n",
    "                                                      'l4ab':l4ab,\n",
    "                                                      'l4ca':l4ca,\n",
    "                                                      'l4cb':l4cb,\n",
    "                                                      'l5':l5,\n",
    "                                                      'l6':l6,\n",
    "                                                      'lWM':lWM})\n",
    "\n",
    "    out_layer = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "    display(widgets.HBox([ui,output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369d39c",
   "metadata": {},
   "source": [
    "### Ses. 1 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3d8f05",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb445724d6f4e66bf2c3a93804a932b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=2210, continuous_update=False, description='2/3', max=3000), Int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_picker_output(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bb7e2",
   "metadata": {},
   "source": [
    "### Ses. 2 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ce1794",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bddb311e86418bb08038b916b6fb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=2210, continuous_update=False, description='2/3', max=3000), Int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_picker_output(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b9916",
   "metadata": {},
   "source": [
    "### Ses. 3 Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f071d2d5",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2e8558f725464980ac70f27f170c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=2210, continuous_update=False, description='2/3', max=3000), Int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_picker_output(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a123bd77",
   "metadata": {
    "tags": [
     "size=100"
    ]
   },
   "source": [
    "## Column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb434b8",
   "metadata": {},
   "source": [
    "### Click here to plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bd2a727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1690b3a840b54ea0874ad1118fc43df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='plot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(plot_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c7a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "pre_pair_label = widgets.Label(value=\"Pre:\")\n",
    "pre_opt = [(label, idx+1) for idx, label in enumerate(labels[plot_selection.value])]\n",
    "pre_pair_selection = widgets.RadioButtons(\n",
    "    options=pre_opt,\n",
    "    value=pre_opt[0][1],\n",
    "    disabled=False\n",
    ")\n",
    "post_pair_label = widgets.Label(value=\"Post:\")\n",
    "post_opt =  [(label, idx+1) for idx, label in enumerate(labels[plot_selection.value])]\n",
    "post_pair_selection = widgets.RadioButtons(\n",
    "    options=post_opt,\n",
    "    value=post_opt[0][1],\n",
    "    #layout={'width': 'max-content'},\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59db0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "out0 = widgets.Output()\n",
    "out0s = widgets.Output()\n",
    "\n",
    "out = widgets.Output()\n",
    "outs = widgets.Output()\n",
    "outsi = widgets.Output()\n",
    "\n",
    "out2 = widgets.Output()\n",
    "out2s = widgets.Output()\n",
    "out2si = widgets.Output()\n",
    "\n",
    "out3 = widgets.Output()\n",
    "out3s = widgets.Output()\n",
    "out3si = widgets.Output()\n",
    "\n",
    "out4 = widgets.Output()\n",
    "out4s = widgets.Output()\n",
    "out4si = widgets.Output()\n",
    "\n",
    "out5 = widgets.Output()\n",
    "\n",
    "\n",
    "def on_value_change(change):\n",
    "    ccg_curr, maxima, metric, subset  = get_subset(change)\n",
    "    plot_type = plot_selection.value;\n",
    "    row_labels = labels[plot_type]\n",
    "    num_rows = len(row_labels);\n",
    "    pre_lab = \"pre_\" + plot_type\n",
    "    post_lab = \"post_\" + plot_type\n",
    "    \n",
    "    with out0: \n",
    "        ex_ccgs = ccg_curr['ccgs']\n",
    "        ex_idxes = np.random.choice(ex_ccgs.shape[0], size = 4, replace=True)\n",
    "        \n",
    "        out0.clear_output(wait=False)\n",
    "        for idx, example in enumerate(ex_idxes):\n",
    "            plt.subplot(2,2,idx+1)\n",
    "            h = plt.plot(range(-10, -10 + ex_ccgs[example].size),ex_ccgs[example], 'o-')\n",
    "            if idx>1:\n",
    "                plt.xlabel(\"tau\")\n",
    "            if idx == 0 or idx == 2:\n",
    "                plt.ylabel(metric)\n",
    "            plt.tight_layout()\n",
    "                \n",
    "        plt.show()\n",
    "        \n",
    "    with out:\n",
    "        cont_mtx = make_cont_mtx(ccg_curr[pre_lab], ccg_curr[post_lab], ccg_curr[maxima+'_lag'], num_rows)\n",
    "        df = pd.DataFrame(cont_mtx, columns=row_labels, index=row_labels)\n",
    "        \n",
    "        out.clear_output(wait=False)\n",
    "        sns.heatmap(df, annot=True)\n",
    "        plt.xlabel('post-syn. neuron')\n",
    "        plt.ylabel('pre-syn. neuron')\n",
    "        plt.title(\"mean lead (ms), n = \" + str(ccg_curr[pre_lab].size))\n",
    "        plt.show()\n",
    "    \n",
    "    with out2:\n",
    "        cont_mtx = make_cont_mtx(ccg_curr[pre_lab], ccg_curr[post_lab], ccg_curr[maxima+'s'], num_rows)\n",
    "        df = pd.DataFrame(cont_mtx, columns=row_labels, index=row_labels)\n",
    "        \n",
    "        out2.clear_output(wait=False)\n",
    "        sns.heatmap(df, cmap='YlOrBr', annot=True)\n",
    "        plt.xlabel('post-syn. neuron')\n",
    "        plt.ylabel('pre-syn. neuron')\n",
    "        plt.title(\"mean maxima (ms), n = \" + str(ccg_curr[pre_lab].size))\n",
    "        plt.show()\n",
    "        \n",
    "    with out3:\n",
    "        mtx, numer, denom = make_prop_mtx(ccg_curr[pre_lab], ccg_curr[post_lab], ccg_curr['peak_lag']>-1, num_rows)\n",
    "        prop_mtx = np.divide(numer, numer + np.transpose(numer));\n",
    "        df = pd.DataFrame(prop_mtx, columns=row_labels, index=row_labels)\n",
    "        \n",
    "        out3.clear_output(wait=False)\n",
    "        sns.heatmap(df, cmap='vlag', center=.5, annot=True) #, annot=True\n",
    "        plt.xlabel('neuron k')\n",
    "        plt.ylabel('neuron j')\n",
    "        plt.title(\"prop. j leads k, n = \" + str(ccg_curr[pre_lab].size))\n",
    "        plt.show()\n",
    "    \n",
    "    with out4:\n",
    "        ccg_pre_subset = ccg_data[metric][0][0].copy()\n",
    "        mtx, numer, denom = make_prop_mtx(ccg_pre_subset[pre_lab], ccg_pre_subset[post_lab], subset, num_rows)\n",
    "        df = pd.DataFrame(mtx, columns=row_labels, index=row_labels)\n",
    "        \n",
    "        out4.clear_output(wait=False)\n",
    "        sns.heatmap(df, cmap='YlOrBr', annot=True) #, annot=True\n",
    "        plt.xlabel('neuron k')\n",
    "        plt.ylabel('neuron j')\n",
    "        plt.title(\"prop. sig, n = \" + str(ccg_curr[pre_lab].size) + \"/\" + str(ccg_pre_subset[pre_lab].size))\n",
    "        plt.show()\n",
    "    \n",
    "    with out5:\n",
    "        ccg_fields = ccg_data['ccg'][0][0].dtype.names\n",
    "        ccgs = ccg_curr['ccgs']\n",
    "        \n",
    "        out5.clear_output(wait=False)\n",
    "        subset, smoothed, cluster_obj = cluster_flow(ccgs)\n",
    "\n",
    "        for field in ccg_fields:\n",
    "            if field != 'config' and field != 'cluster' and field != 'ccg_control':\n",
    "                ccg_curr[field] = ccg_curr[field][np.squeeze(subset)]\n",
    "\n",
    "        #plot_cluster_network(cluster_obj.labels_, ccg_curr)\n",
    "        plot_cluster_examples(smoothed, cluster_obj.labels_+1)\n",
    "        plot_cluster_templates(smoothed, cluster_obj.labels_+1)\n",
    "        #plot_cluster_bars()\n",
    "        plot_dendrogram(cluster_obj, truncate_mode='level', p=3)\n",
    "        plot_cluster_heatmaps(cluster_obj.labels_, ccg_curr, 'pre_cl', 'post_cl', len(labels['cl']), labels['cl'])\n",
    "\n",
    "    on_pairwise_change(change)\n",
    "\n",
    "def on_metric_change(change):\n",
    "    metric = ccg_selection.value\n",
    "    maxima = maxima_selection.value\n",
    "    ccg_curr = ccg_data[metric][0][0].copy()\n",
    "\n",
    "    maxima_val = ccg_curr[maxima+'s']\n",
    "    maxima_noise = ccg_curr['noise_std' + noise_selection.value]\n",
    "    maxima_noise_mean = ccg_curr['noise_mean'+ noise_selection.value]\n",
    "    maxima_area = np.squeeze(ccg_curr['area'])\n",
    "\n",
    "    sd_inclusion = np.squeeze((maxima_val-maxima_noise_mean)/maxima_noise);\n",
    "    \n",
    "    nan_mask = np.logical_or.reduce((np.isnan(sd_inclusion), np.isnan(maxima_area), np.isinf(sd_inclusion), np.isinf(maxima_area)))\n",
    "    xrange_mask = np.logical_and(sd_inclusion<=10, sd_inclusion>=0)\n",
    "    yrange_mask = np.logical_and(maxima_area>=-.1, maxima_area<=.1)\n",
    "    data_mask = np.logical_and.reduce((~nan_mask, xrange_mask, yrange_mask))\n",
    "    \n",
    "    with out0s:\n",
    "        out0s.clear_output(wait=False)\n",
    "        fig = sns.jointplot(x=sd_inclusion[data_mask], y=maxima_area[data_mask], kind='hist',dropna=True, xlim=(0, 10), ylim=(-.1, .1))     \n",
    "        fig.set_axis_labels(\"x SDs above noise mean\",\"ccg area\")\n",
    "        plt.show()\n",
    "        \n",
    "def on_plot_type_change(change):        \n",
    "    plot_type = plot_selection.value;    \n",
    "    pre_opt = [(label, idx+1) for idx, label in enumerate(labels[plot_type])]\n",
    "    pre_pair_selection.value = pre_opt[0][1]\n",
    "    pre_pair_selection.options = pre_opt\n",
    "    \n",
    "    post_opt = [(label, idx+1) for idx, label in enumerate(labels[plot_type])]\n",
    "    post_pair_selection.value = post_opt[0][1]\n",
    "    post_pair_selection.options = post_opt\n",
    "    \n",
    "    with outsi:\n",
    "        outsi.clear_output(wait=False)\n",
    "        display(widgets.HBox([widgets.VBox([pre_pair_label, pre_pair_selection]), widgets.VBox([post_pair_label, post_pair_selection])]))\n",
    "    \n",
    "    with out2si:\n",
    "        out2si.clear_output(wait=False)\n",
    "        display(widgets.HBox([widgets.VBox([pre_pair_label, pre_pair_selection]), widgets.VBox([post_pair_label, post_pair_selection])]))\n",
    "    \n",
    "    with out3si:\n",
    "        out3si.clear_output(wait=False)\n",
    "        display(widgets.HBox([widgets.VBox([pre_pair_label, pre_pair_selection]), widgets.VBox([post_pair_label, post_pair_selection])]))\n",
    "\n",
    "    with out4si:\n",
    "        out4si.clear_output(wait=False)\n",
    "        display(widgets.HBox([widgets.VBox([pre_pair_label, pre_pair_selection]), widgets.VBox([post_pair_label, post_pair_selection])]))\n",
    "        \n",
    "    on_pairwise_change(change)\n",
    "\n",
    "def on_pairwise_change(change):\n",
    "    ccg_curr, maxima, metric, subset  = get_subset(change)\n",
    "    plot_type = plot_selection.value;\n",
    "    row_labels = labels[plot_type]\n",
    "    num_rows = len(row_labels);\n",
    "    pre_lab = \"pre_\" + plot_type\n",
    "    post_lab = \"post_\" + plot_type\n",
    "    \n",
    "    pre_to_post = np.squeeze(np.logical_and(ccg_curr[pre_lab] == pre_pair_selection.value, ccg_curr[post_lab] ==post_pair_selection.value))\n",
    "    post_to_pre = np.squeeze(np.logical_and(ccg_curr[post_lab] == pre_pair_selection.value, ccg_curr[pre_lab] ==post_pair_selection.value))\n",
    "    conx_labels = {1: \"pre->post\", 2: \"post->pre\", 0: \"other\"}        \n",
    "\n",
    "    with outs:\n",
    "        lag = np.squeeze(ccg_curr[maxima+'_lag'])\n",
    "        connection = pd.Categorical(np.append(pre_to_post, 2*post_to_pre)).rename_categories(conx_labels)\n",
    "        lag = np.append(lag, lag)\n",
    "        df = pd.DataFrame({'lead':lag, 'connection':connection})\n",
    "        \n",
    "        outs.clear_output(wait=False)\n",
    "        sns.histplot(data=df, x='lead', hue=\"connection\", stat=\"density\", common_norm=False, fill=False)\n",
    "        plt.show()\n",
    "    \n",
    "    with out2s:   \n",
    "        lag = np.squeeze(ccg_curr[maxima+'s'])\n",
    "        lag = np.append(lag, lag)\n",
    "            \n",
    "        connection = pd.Categorical(np.append(pre_to_post, 2*post_to_pre)).rename_categories(conx_labels)\n",
    "        df = pd.DataFrame({maxima:lag, 'connection':connection})\n",
    "        \n",
    "        out2s.clear_output(wait=False)\n",
    "        sns.histplot(data=df, x=maxima, hue=\"connection\", stat=\"density\", common_norm=False, fill=False)\n",
    "        plt.show()\n",
    "        \n",
    "    with out3s:\n",
    "        data = np.append(-1*ccg_curr[maxima+'_lag'][pre_to_post], ccg_curr[maxima+'_lag'][post_to_pre])\n",
    "        data = data[data!=0]\n",
    "        out3s.clear_output(wait=False)\n",
    "        sns.histplot(x=data, stat=\"density\", fill=False, bins=21)\n",
    "        plt.show()\n",
    "        \n",
    "    with out4s:\n",
    "        ccg_pre_subset = ccg_data[metric][0][0].copy()\n",
    "        all_pre_to_post = np.squeeze(np.logical_and(ccg_pre_subset[pre_lab] == pre_pair_selection.value, ccg_pre_subset[post_lab] ==post_pair_selection.value))\n",
    "        all_post_to_pre = np.squeeze(np.logical_and(ccg_pre_subset[post_lab] == pre_pair_selection.value, ccg_pre_subset[pre_lab] ==post_pair_selection.value))\n",
    "  \n",
    "        sig_notsig = np.zeros((2,2))\n",
    "        sig_notsig[0,0] =  np.sum(pre_to_post) # sig + pre->post\n",
    "        sig_notsig[0,1] =  np.sum(all_pre_to_post)-np.sum(pre_to_post)# notsig + pre->post\n",
    "        sig_notsig[1,0] =  np.sum(post_to_pre) # sig + post->pre\n",
    "        sig_notsig[1,1] =  np.sum(all_post_to_pre)-np.sum(post_to_pre)# notsig + post-> pre\n",
    "        \n",
    "        g, p, dof, expctd = chi2_contingency(sig_notsig)\n",
    "        \n",
    "        out4s.clear_output(wait=False)\n",
    "        \n",
    "        print(\"Chi^2 test: chi^2 = \" + str(g) + \" p = \" + str(p))\n",
    "\n",
    "def on_click_reset(change):\n",
    "    if default_selection.value == \"sd_area\":\n",
    "        plot_selection.value = 'cl'\n",
    "        ccg_selection.value = 'ccg'\n",
    "        maxima_selection.value = 'peak'\n",
    "        area_selection.value = (.05,.5)\n",
    "        lag_selection.value = (0,10)\n",
    "        std_selection.value = (3,10)\n",
    "    elif default_selection.value == \"sd\":\n",
    "        plot_selection.value = 'cl'\n",
    "        ccg_selection.value = 'ccgn'\n",
    "        maxima_selection.value = 'peak'\n",
    "        area_selection.value = (-.5,.5)\n",
    "        lag_selection.value = (0,10)\n",
    "        std_selection.value = (5,10)\n",
    "    else:\n",
    "        error(\"wrong\")\n",
    "\n",
    "#for cbox in ct_checkboxes:\n",
    "#    cbox.observe(on_value_change, names=\"value\")\n",
    "#for cbox in cl_checkboxes:\n",
    "#    cbox.observe(on_value_change, names=\"value\")\n",
    "#for cbox in sc_checkboxes:\n",
    "#    cbox.observe(on_value_change, names=\"value\")\n",
    "\n",
    "\n",
    "#plot_selection.observe(on_value_change, names=\"value\")\n",
    "#ccg_selection.observe(on_value_change, names=\"value\")\n",
    "#noise_selection.observe(on_value_change, names=\"value\")\n",
    "#maxima_selection.observe(on_value_change, names=\"value\")\n",
    "#area_selection.observe(on_value_change, names=\"value\")\n",
    "#lag_selection.observe(on_value_change, names=\"value\")\n",
    "#std_selection.observe(on_value_change, names=\"value\")\n",
    "\n",
    "plot_button.on_click(on_value_change)\n",
    "\n",
    "plot_selection.observe(on_plot_type_change, names=\"value\")\n",
    "\n",
    "pre_pair_selection.observe(on_pairwise_change, names=\"value\")\n",
    "post_pair_selection.observe(on_pairwise_change, names=\"value\")\n",
    "\n",
    "ccg_selection.observe(on_metric_change, names=\"value\")\n",
    "maxima_selection.observe(on_metric_change, names=\"value\")\n",
    "\n",
    "default_button.on_click(on_click_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805e413",
   "metadata": {},
   "source": [
    "# CCG Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f373af1",
   "metadata": {
    "tags": [
     "size=600"
    ]
   },
   "source": [
    "## Column 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b373831",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f99e65bb",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3298ede53694fb28293e278b281876c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "on_value_change(None)\n",
    "out0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481eecf",
   "metadata": {
    "tags": [
     "size=400"
    ]
   },
   "source": [
    "## Column 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a0a8a",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73fcef64",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5d766c860a4607bb1383983048de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "on_metric_change(None)\n",
    "out0s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0692f3",
   "metadata": {},
   "source": [
    "# |Tau| Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7417062",
   "metadata": {
    "tags": [
     "size=600"
    ]
   },
   "source": [
    "## Column 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85aaf15",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8419db8",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ea1d58f241489e9aea70ff3612d046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f1498",
   "metadata": {
    "tags": [
     "size=400"
    ]
   },
   "source": [
    "## Column 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d6a1c",
   "metadata": {},
   "source": [
    "### Pairwise Test Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fdc1fb7",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc636d76e592418590f7a5942b6d53f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "on_plot_type_change(None)\n",
    "outsi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ddd85",
   "metadata": {},
   "source": [
    "### Pairwise Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c37d7b50",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40380187b1e7441183cd18ae5027ab4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ceb8ab",
   "metadata": {},
   "source": [
    "# Maxima Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211199e5",
   "metadata": {
    "tags": [
     "size=600"
    ]
   },
   "source": [
    "## Column 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb00656",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef5b8905",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c129e26012b44807bf2e4e3cdcf8fd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c4916",
   "metadata": {
    "tags": [
     "size=400"
    ]
   },
   "source": [
    "## Column 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6bab91",
   "metadata": {},
   "source": [
    "### Pairwise Test Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23a8d6c9",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f96b573b4724f5888904ac9a941e258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out2si"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed420e1",
   "metadata": {},
   "source": [
    "### Pairwise Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd4803f6",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2eeda63afa479196776ebad41a35b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out2s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d9f45",
   "metadata": {},
   "source": [
    "# Prop. j leads k Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b01508",
   "metadata": {
    "tags": [
     "size=600"
    ]
   },
   "source": [
    "## Column 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3ddfd",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2075079",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a758e18c174091940de4ac57a0acc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791fd3e",
   "metadata": {
    "tags": [
     "size=400"
    ]
   },
   "source": [
    "## Column 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d64eed",
   "metadata": {},
   "source": [
    "### Pairwise Test Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37cf53cb",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6722e27a1a4ce099b9288c5f1800eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out3si"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdcff41",
   "metadata": {},
   "source": [
    "### Pairwise Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "041f2ec9",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a6411505fc4a67a1ea493e98c1604a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out3s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631381d1",
   "metadata": {},
   "source": [
    "# Prop. significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29542e",
   "metadata": {
    "tags": [
     "size=600"
    ]
   },
   "source": [
    "## Column 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1f157",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc6077c6",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913e07324daa4f209765155426b55265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e572c6",
   "metadata": {
    "tags": [
     "size=400"
    ]
   },
   "source": [
    "## Column 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d669ee",
   "metadata": {},
   "source": [
    "### Pairwise Test Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45e3de67",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d0912822e9409d8f487eb0d60612a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out4si"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4281cd0",
   "metadata": {},
   "source": [
    "### Pairwise Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5b9c8cc",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9abec64698441c8c9f334f7d713fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out4s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3f257",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973d4d1",
   "metadata": {},
   "source": [
    "## Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d18b8a",
   "metadata": {},
   "source": [
    "### Cluster Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd9e9321",
   "metadata": {
    "tags": [
     "body"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203653a058b844f18673c1c967d2d26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd4ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
